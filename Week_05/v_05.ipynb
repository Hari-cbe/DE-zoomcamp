{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b0da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29c78b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40335b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/27 13:25:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .appName(\"v_05\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f8aaa",
   "metadata": {},
   "source": [
    "Reading the partition parquet file\n",
    "\n",
    "Parquet will remember the schema type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84069079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fhvhv/2021/01/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47199870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- originating_base_num: string (nullable = true)\n",
      " |-- request_datetime: timestamp (nullable = true)\n",
      " |-- on_scene_datetime: timestamp (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- trip_time: long (nullable = true)\n",
      " |-- base_passenger_fare: double (nullable = true)\n",
      " |-- tolls: double (nullable = true)\n",
      " |-- bcf: double (nullable = true)\n",
      " |-- sales_tax: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- driver_pay: double (nullable = true)\n",
      " |-- shared_request_flag: string (nullable = true)\n",
      " |-- shared_match_flag: string (nullable = true)\n",
      " |-- access_a_ride_flag: string (nullable = true)\n",
      " |-- wav_request_flag: string (nullable = true)\n",
      " |-- wav_match_flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132801b",
   "metadata": {},
   "source": [
    "<h3> Transformations & Actions </h3>\n",
    "\n",
    "Transformation -> <br>lazy functions <br> \n",
    "Eg., select, filter, joins, groupby \n",
    "\n",
    "Actions -> <br>\n",
    "Imediate functions <br>\n",
    "Eg., show, head, write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cbfee8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+------------+----------+\n",
      "|hvfhs_license_num|PULocationID|DOLocationID|trip_miles|\n",
      "+-----------------+------------+------------+----------+\n",
      "|           HV0004|         162|           1|     16.21|\n",
      "|           HV0004|         225|          17|      1.17|\n",
      "|           HV0004|         221|          67|      6.44|\n",
      "|           HV0004|         107|         166|      5.96|\n",
      "|           HV0004|          74|         143|      3.96|\n",
      "|           HV0004|         243|          60|      4.72|\n",
      "|           HV0004|         225|          61|      1.08|\n",
      "|           HV0004|         158|          75|      6.82|\n",
      "|           HV0004|         232|         236|      7.15|\n",
      "|           HV0004|         141|         138|       6.9|\n",
      "|           HV0004|         151|         166|      1.09|\n",
      "|           HV0004|         113|         114|      1.16|\n",
      "|           HV0004|         116|         100|      6.21|\n",
      "|           HV0004|         246|         249|      1.58|\n",
      "|           HV0004|          48|         239|      2.94|\n",
      "|           HV0004|         243|         243|      0.68|\n",
      "|           HV0004|         151|         243|      7.25|\n",
      "|           HV0004|          61|         256|      3.24|\n",
      "|           HV0004|         170|          90|      2.21|\n",
      "|           HV0004|         229|         107|      2.53|\n",
      "+-----------------+------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('hvfhs_license_num','PULocationID','DOLocationID','trip_miles')\\\n",
    "    .filter(df['hvfhs_license_num'] == 'HV0004')\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f86d51",
   "metadata": {},
   "source": [
    "<h3> Functions & User Defined Functions <h3>\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ecbd83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d43e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F.to_date() -> takes the datetime datatype and changes to the date column datatype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88c76a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+------------+------------+------------+----------+\n",
      "|hvfhs_license_num|pickup_date|PULocationID|dropoff_date|DOLocationID|trip_miles|\n",
      "+-----------------+-----------+------------+------------+------------+----------+\n",
      "|           HV0003| 2021-01-11|         262|  2021-01-11|         231|      9.61|\n",
      "|           HV0003| 2021-01-05|          61|  2021-01-05|         181|      2.86|\n",
      "|           HV0005| 2021-01-02|         100|  2021-01-02|           1|    16.899|\n",
      "|           HV0003| 2021-01-31|         232|  2021-01-31|           4|      1.51|\n",
      "|           HV0004| 2021-01-05|         162|  2021-01-05|           1|     16.21|\n",
      "|           HV0003| 2021-01-27|          68|  2021-01-27|          68|       0.2|\n",
      "|           HV0005| 2021-01-18|         205|  2021-01-18|         205|     1.448|\n",
      "|           HV0003| 2021-01-30|         256|  2021-01-30|         255|      0.58|\n",
      "|           HV0003| 2021-01-16|          89|  2021-01-16|          91|      2.05|\n",
      "|           HV0005| 2021-01-05|         132|  2021-01-05|         102|    10.505|\n",
      "|           HV0003| 2021-01-11|          97|  2021-01-11|          61|      2.76|\n",
      "|           HV0005| 2021-01-22|          79|  2021-01-22|          37|     6.585|\n",
      "|           HV0003| 2021-01-03|          26|  2021-01-03|         178|      3.06|\n",
      "|           HV0003| 2021-01-14|         181|  2021-01-14|         198|       5.1|\n",
      "|           HV0003| 2021-01-08|          76|  2021-01-08|          91|      6.26|\n",
      "|           HV0003| 2021-01-15|         246|  2021-01-15|          16|     15.67|\n",
      "|           HV0003| 2021-01-27|         135|  2021-01-27|          73|      4.64|\n",
      "|           HV0005| 2021-01-18|          74|  2021-01-18|         234|     6.122|\n",
      "|           HV0003| 2021-01-11|          68|  2021-01-11|         211|      2.94|\n",
      "|           HV0003| 2021-01-24|         249|  2021-01-24|         236|      4.66|\n",
      "+-----------------+-----------+------------+------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"pickup_date\",F.to_date(df['pickup_datetime']))\\\n",
    "    .withColumn(\"dropoff_date\",F.to_date(df['dropoff_datetime']))\\\n",
    "    .select('hvfhs_license_num','pickup_date','PULocationID','dropoff_date','DOLocationID','trip_miles')\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2534488",
   "metadata": {},
   "source": [
    "UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b9daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkOddEven(base_num):\n",
    "    num = base_num[1:]\n",
    "    if num % 2 == 0:\n",
    "        return f'even/{num:1x}'\n",
    "    else:\n",
    "        return f'odd/{num:1x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a594a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function _create_udf at 0x7f79c460dbc0>, returnType=StringType(), evalType=100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.udf("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
